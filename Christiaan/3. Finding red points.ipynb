{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b791b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from ipywidgets import widgets, VBox, HBox\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4f34c",
   "metadata": {},
   "source": [
    "### Image Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085680fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('../../../data/Patch Perfect Data/train_labels.csv')\n",
    "test_labels = pd.read_csv('../../../data/Patch Perfect Data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01dbe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['Bags used '].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc11ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.columns = ['pothole_id', 'bags_used']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30858a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['pothole_id'] = 'p'+(train_labels['pothole_id']).astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e1fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e88fe",
   "metadata": {},
   "source": [
    "### Image annotations - bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845eb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(annotation_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(annotation_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            pothole_id = filename.split('.')[0]\n",
    "            with open(os.path.join(annotation_path, filename), 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    data.append({\n",
    "                        'pothole_id': pothole_id,\n",
    "                        'class': int(parts[0]),\n",
    "                        'x': float(parts[1]),\n",
    "                        'y': float(parts[2]),\n",
    "                        'width': float(parts[3]),\n",
    "                        'height': float(parts[4])\n",
    "                    })\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49470c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = load_annotations('../../../data/Patch Perfect Data/train_annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65802bae",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.jpg'):\n",
    "            img = cv2.imread(os.path.join(folder, filename))\n",
    "            if img is not None:\n",
    "                pothole_id = filename.split('.')[0]\n",
    "                data.append({'pothole_id': pothole_id, 'image': img})\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcdde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_images_from_folder('../../../data/Patch Perfect Data/train_images')\n",
    "test_images = load_images_from_folder('../../../data/Patch Perfect Data/test_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95243bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134c9ff",
   "metadata": {},
   "source": [
    "## Filtering out images with no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c71e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = train_labels[train_labels['pothole_id'].isin(set(train_images['pothole_id']))]['pothole_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_images = train_images[train_images['pothole_id'].isin(set(valid_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8968077",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = train_labels[train_labels['pothole_id'].isin(set(valid_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971434d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_labels.shape)\n",
    "print(valid_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(valid_ids, columns=['pothole_id']).to_csv('data/valid_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aee71ee",
   "metadata": {},
   "source": [
    "# Finding red points of L1 stick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ac384",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(valid_ids, columns=['pothole_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39eee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('YOLO/L1/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca700d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_red_centroids_in_bbox(image, bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "    hsv_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_red = np.array([0, 100, 100])\n",
    "    upper_red = np.array([10, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv_cropped, lower_red, upper_red)\n",
    "\n",
    "    lower_red = np.array([160, 100, 100])\n",
    "    upper_red = np.array([180, 255, 255])\n",
    "    mask2 = cv2.inRange(hsv_cropped, lower_red, upper_red)\n",
    "\n",
    "    mask = mask1 + mask2\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    height, width = cropped_image.shape[:2]\n",
    "    half_width = width // 2\n",
    "    half_height = height // 2\n",
    "\n",
    "    left_half_centroids = []\n",
    "    right_half_centroids = []\n",
    "    top_half_centroids = []\n",
    "    bottom_half_centroids = []\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        M = cv2.moments(contour)\n",
    "        if M['m00'] != 0:\n",
    "            cX = int(M['m10'] / M['m00'])\n",
    "            cY = int(M['m01'] / M['m00'])\n",
    "            \n",
    "            # Determine if the rectangle is vertical or horizontal\n",
    "            if height > width:  # Vertical orientation\n",
    "                if cY < half_height:\n",
    "                    top_half_centroids.append((cX + x1, cY + y1, area))\n",
    "                else:\n",
    "                    bottom_half_centroids.append((cX + x1, cY + y1, area))\n",
    "            else:  # Horizontal orientation\n",
    "                if cX < half_width:\n",
    "                    left_half_centroids.append((cX + x1, cY + y1, area))\n",
    "                else:\n",
    "                    right_half_centroids.append((cX + x1, cY + y1, area))\n",
    "\n",
    "    def select_largest_area(centroids):\n",
    "        if not centroids:\n",
    "            return None\n",
    "        return max(centroids, key=lambda x: x[2])\n",
    "\n",
    "    if height > width:  # Vertical orientation\n",
    "        top_centroid = select_largest_area(top_half_centroids)\n",
    "        bottom_centroid = select_largest_area(bottom_half_centroids)\n",
    "\n",
    "        if not top_centroid:\n",
    "            top_centroid = (x1 + width // 2, y1 + int(height * 0.1))\n",
    "\n",
    "        if not bottom_centroid:\n",
    "            bottom_centroid = (x1 + width // 2, y2 - int(height * 0.1))\n",
    "\n",
    "        return [top_centroid, bottom_centroid]\n",
    "    else:  # Horizontal orientation\n",
    "        left_centroid = select_largest_area(left_half_centroids)\n",
    "        right_centroid = select_largest_area(right_half_centroids)\n",
    "\n",
    "        if not left_centroid:\n",
    "            left_centroid = (x1 + int(width * 0.1), y1 + height // 2)\n",
    "\n",
    "        if not right_centroid:\n",
    "            right_centroid = (x2 - int(width * 0.1), y1 + height // 2)\n",
    "\n",
    "        return [left_centroid, right_centroid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf976b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "red_point_1_x = []\n",
    "red_point_1_y = []\n",
    "red_point_2_x = []\n",
    "red_point_2_y = []\n",
    "\n",
    "# Iterate over each image in valid_ids\n",
    "for pothole_id in valid_ids:\n",
    "    # Get the image corresponding to the pothole_id\n",
    "    image = train_images[train_images['pothole_id'] == pothole_id]['image'].values[0]\n",
    "\n",
    "    # Step 1: Detect the L1 bounding box using the model\n",
    "    l1_results = model.predict(source=image, save=False, verbose=False)\n",
    "\n",
    "    # Ensure there are detections\n",
    "    if len(l1_results[0].boxes) > 0:\n",
    "        # Get the bounding box with the highest confidence\n",
    "        l1_boxes = l1_results[0].boxes.xyxy.cpu().numpy()\n",
    "        l1_confidences = l1_results[0].boxes.conf.cpu().numpy()\n",
    "        l1_max_conf_idx = np.argmax(l1_confidences)\n",
    "        l1_bbox = l1_boxes[l1_max_conf_idx].astype(int)\n",
    "\n",
    "        # Step 2: Find the red centroids in the L1 bounding box\n",
    "        red_centroids = find_red_centroids_in_bbox(image, l1_bbox)\n",
    "\n",
    "        # Store the red points if they are found\n",
    "        if len(red_centroids) == 2:\n",
    "            red_point_1_x.append(red_centroids[0][0])\n",
    "            red_point_1_y.append(red_centroids[0][1])\n",
    "            red_point_2_x.append(red_centroids[1][0])\n",
    "            red_point_2_y.append(red_centroids[1][1])\n",
    "        else:\n",
    "            # If centroids are not found, store None\n",
    "            red_point_1_x.append(None)\n",
    "            red_point_1_y.append(None)\n",
    "            red_point_2_x.append(None)\n",
    "            red_point_2_y.append(None)\n",
    "    else:\n",
    "        # If no L1 bounding box is detected, store None\n",
    "        red_point_1_x.append(None)\n",
    "        red_point_1_y.append(None)\n",
    "        red_point_2_x.append(None)\n",
    "        red_point_2_y.append(None)\n",
    "\n",
    "# Add the red points to the train_df dataframe\n",
    "train_df['red_point_1_x'] = red_point_1_x\n",
    "train_df['red_point_1_y'] = red_point_1_y\n",
    "train_df['red_point_2_x'] = red_point_2_x\n",
    "train_df['red_point_2_y'] = red_point_2_y\n",
    "\n",
    "# Display the updated dataframe\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d697dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7929b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869775ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
