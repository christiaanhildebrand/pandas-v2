{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f187ea6",
   "metadata": {},
   "source": [
    "# Pothole Bounding Box Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587bbbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from ipywidgets import widgets, VBox, HBox\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a6712",
   "metadata": {},
   "source": [
    "# Start from Fine Tuning Model section to only train model!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a1233",
   "metadata": {},
   "source": [
    "## Importing Images and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4f34c",
   "metadata": {},
   "source": [
    "### Image Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085680fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('../../../data/Patch Perfect Data/train_labels.csv')\n",
    "test_labels = pd.read_csv('../../../data/Patch Perfect Data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f0603",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01dbe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['Bags used '].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc11ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.columns = ['pothole_id', 'bags_used']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30858a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['pothole_id'] = 'p'+(train_labels['pothole_id']).astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e1fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3e88fe",
   "metadata": {},
   "source": [
    "### Image annotations - bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845eb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(annotation_path):\n",
    "    data = []\n",
    "    for filename in os.listdir(annotation_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            pothole_id = filename.split('.')[0]\n",
    "            with open(os.path.join(annotation_path, filename), 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    data.append({\n",
    "                        'pothole_id': pothole_id,\n",
    "                        'class': int(parts[0]),\n",
    "                        'x': float(parts[1]),\n",
    "                        'y': float(parts[2]),\n",
    "                        'width': float(parts[3]),\n",
    "                        'height': float(parts[4])\n",
    "                    })\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49470c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = load_annotations('../../../data/Patch Perfect Data/train_annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65802bae",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.jpg'):\n",
    "            img = cv2.imread(os.path.join(folder, filename))\n",
    "            if img is not None:\n",
    "                pothole_id = filename.split('.')[0]\n",
    "                data.append({'pothole_id': pothole_id, 'image': img})\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcdde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_images_from_folder('../../../data/Patch Perfect Data/train_images')\n",
    "test_images = load_images_from_folder('../../../data/Patch Perfect Data/test_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95243bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2931efc0",
   "metadata": {},
   "source": [
    "## Visualising images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce5268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image, annotations):\n",
    "    for _, row in annotations.iterrows():\n",
    "        img_height, img_width, _ = image.shape\n",
    "        x_center = int(row['x'] * img_width)\n",
    "        y_center = int(row['y'] * img_height)\n",
    "        box_width = int(row['width'] * img_width)\n",
    "        box_height = int(row['height'] * img_height)\n",
    "        \n",
    "        x1 = int(x_center - box_width / 2)\n",
    "        y1 = int(y_center - box_height / 2)\n",
    "        x2 = int(x_center + box_width / 2)\n",
    "        y2 = int(y_center + box_height / 2)\n",
    "        \n",
    "        color = (0, 255, 0) if row['class'] == 0 else (255, 0, 0)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c146738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_base64(image):\n",
    "    _, buffer = cv2.imencode('.jpg', image)\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    buffered = BytesIO()\n",
    "    pil_img.save(buffered, format=\"JPEG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "    return \"data:image/jpeg;base64,\" + img_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image_record = train_images.iloc[0]\n",
    "first_image_id = first_image_record['pothole_id']\n",
    "first_image = first_image_record['image']\n",
    "first_image_annotations = train_annotations[train_annotations['pothole_id'] == first_image_id]\n",
    "first_image_with_boxes = draw_bounding_boxes(first_image.copy(), first_image_annotations)\n",
    "first_image_base64 = convert_image_to_base64(first_image_with_boxes)\n",
    "first_image_label = train_labels[train_labels['pothole_id'] == first_image_id].iloc[:,1].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c533dc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Add initial image\n",
    "fig.add_trace(go.Image(source=first_image_base64))\n",
    "\n",
    "# Generate dropdown options\n",
    "dropdown_buttons = []\n",
    "for pothole_id in train_images['pothole_id']:\n",
    "    image = train_images[train_images['pothole_id'] == pothole_id].iloc[0]['image'].copy()\n",
    "    annotations = train_annotations[train_annotations['pothole_id'] == pothole_id]\n",
    "    image_with_boxes = draw_bounding_boxes(image, annotations)\n",
    "    image_base64 = convert_image_to_base64(image_with_boxes)\n",
    "    bags_used = train_labels[train_labels['pothole_id'] == pothole_id]['bags_used'].values\n",
    "\n",
    "    dropdown_buttons.append({\n",
    "        \"args\": [{\"source\": image_base64}, {\"title\": f\"Image ID: {pothole_id} | Bags Used: {bags_used}\"}],\n",
    "        \"label\": pothole_id,\n",
    "        \"method\": \"update\"\n",
    "    })\n",
    "\n",
    "# Update layout for dropdown\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        {\n",
    "            \"buttons\": dropdown_buttons,\n",
    "            \"direction\": \"down\",\n",
    "            \"showactive\": True,\n",
    "        }\n",
    "    ],\n",
    "    xaxis=dict(showticklabels=False),\n",
    "    yaxis=dict(showticklabels=False),\n",
    "    title=f\"Image ID: {first_image_id} | Bags Used: {first_image_label}\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c707d4",
   "metadata": {},
   "source": [
    "## Creating YOLO environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9607ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify potholes containing class 0\n",
    "potholes_with_class_0 = set(train_annotations[train_annotations['class'] == 0]['pothole_id'])\n",
    "\n",
    "# Filter annotations to only include those with class 0 and exclude class 1 and class 2\n",
    "annotations_with_class_0 = train_annotations[(train_annotations['pothole_id'].isin(potholes_with_class_0)) & (train_annotations['class'] == 0)]\n",
    "\n",
    "# Filter train_images to only include those with class 0\n",
    "train_images_with_class_0 = train_images[train_images['pothole_id'].isin(potholes_with_class_0)]\n",
    "\n",
    "# Identify potholes that do not contain class 0\n",
    "potholes_without_class_0 = set(train_annotations['pothole_id']) - potholes_with_class_0\n",
    "\n",
    "# Filter annotations to only include those without class 0 (if needed, this will exclude class 0)\n",
    "annotations_without_class_0 = train_annotations[train_annotations['pothole_id'].isin(potholes_without_class_0)]\n",
    "\n",
    "# Filter train_images to only include those without class 0\n",
    "train_images_without_class_0 = train_images[train_images['pothole_id'].isin(potholes_without_class_0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_with_class_0['pothole_id'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_with_class_0_no_duplicates = annotations_with_class_0.drop_duplicates(subset=['pothole_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_with_class_0_no_duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0045157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_yolo_format(image, bboxes):\n",
    "    \"\"\"\n",
    "    Convert bounding box data from your format (x, y, width, height) to YOLO format.\n",
    "    \"\"\"\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    \n",
    "    yolo_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        # The x and y in your data are already the center of the bounding box in normalized form\n",
    "        x_center = bbox['x']\n",
    "        y_center = bbox['y']\n",
    "        width = bbox['width']\n",
    "        height = bbox['height']\n",
    "        \n",
    "        yolo_bboxes.append(f\"{bbox['class']} {x_center} {y_center} {width} {height}\")\n",
    "    \n",
    "    return yolo_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f42ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'YOLO/Pothole ID/images'  # or any directory where you want to save the images\n",
    "label_dir = 'YOLO/Pothole ID/labels'  # directory where labels will be saved\n",
    "\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "# Save images and labels in YOLO format\n",
    "for img, pothole_id in zip(train_images_with_class_0['image'], train_images_with_class_0['pothole_id']):\n",
    "    # Get the bounding boxes for the current image\n",
    "    bboxes = annotations_with_class_0_no_duplicates[annotations_with_class_0_no_duplicates['pothole_id'] == pothole_id].to_dict('records')\n",
    "    \n",
    "    # Save the image\n",
    "    img_path = os.path.join(image_dir, f\"{pothole_id}.jpg\")\n",
    "    cv2.imwrite(img_path, img)\n",
    "    \n",
    "    # Convert bounding boxes to YOLO format\n",
    "    yolo_bboxes = convert_to_yolo_format(img, bboxes)\n",
    "    \n",
    "    # Save the annotations\n",
    "    label_path = os.path.join(label_dir, f\"{pothole_id}.txt\")\n",
    "    with open(label_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(yolo_bboxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b930f3",
   "metadata": {},
   "source": [
    "# FINE TUNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('YOLO/Pothole ID/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    data='YOLO/Pothole ID/data.yaml',  # Path to your data configuration file\n",
    "    epochs=5,  # Number of epochs\n",
    "    imgsz=640,  # Image size\n",
    "    augment=True,  # Enable augmentation\n",
    "    mosaic=1.0,  # Enable mosaic augmentation\n",
    "    mixup=0.0,  # Mixup (not always necessary)\n",
    "    copy_paste=0.0,  # Copy-paste augmentation (optional)\n",
    "    degrees=10.0,  # Random rotation in degrees\n",
    "    translate=0.1,  # Translation (shifting)\n",
    "    scale=0.5,  # Scaling/Zooming\n",
    "    shear=0.0,  # Shearing (usually not necessary)\n",
    "    flipud=0.5,  # Vertical flip probability\n",
    "    fliplr=0.5,  # Horizontal flip probability\n",
    "    hsv_h=0.015,  # HSV-Hue augmentation\n",
    "    hsv_s=0.7,  # HSV-Saturation augmentation\n",
    "    hsv_v=0.4,  # HSV-Value augmentation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('YOLO/Pothole Id/best_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97fb3d9",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b02e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('../OP models/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9188b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.jpg'):\n",
    "            img = cv2.imread(os.path.join(folder, filename))\n",
    "            if img is not None:\n",
    "                pothole_id = filename.split('.')[0]\n",
    "                data.append({'pothole_id': pothole_id, 'image': img})\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635db7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = load_images_from_folder('../../../data/Patch Perfect Data/test_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ea46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_predict(model, images):\n",
    "    \"\"\"\n",
    "    Randomly sample an image, predict the bounding boxes, and plot the image with the highest probable box using PIL.\n",
    "    \n",
    "    Args:\n",
    "    - model: Trained YOLOv8 model.\n",
    "    - images: DataFrame containing images and their associated IDs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Randomly sample an image\n",
    "    sample_row = images.sample(1).iloc[0]\n",
    "    image = sample_row['image']\n",
    "    pothole_id = sample_row['pothole_id']\n",
    "    \n",
    "    # Run prediction\n",
    "    results = model.predict(source=image, save=False)\n",
    "    \n",
    "    if len(results[0].boxes) > 0:\n",
    "        # Extract the predictions\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n",
    "        confidences = results[0].boxes.conf.cpu().numpy()  # Confidence scores\n",
    "        classes = results[0].boxes.cls.cpu().numpy()  # Class labels\n",
    "        \n",
    "        # Find the box with the highest confidence\n",
    "        max_conf_idx = confidences.argmax()\n",
    "        best_box = boxes[max_conf_idx].astype(int)\n",
    "        best_confidence = confidences[max_conf_idx]\n",
    "        best_class = classes[max_conf_idx]\n",
    "        \n",
    "        # Convert image to PIL format\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        draw = ImageDraw.Draw(pil_image)\n",
    "        \n",
    "        # Extract coordinates of the best bounding box\n",
    "        x1, y1, x2, y2 = best_box\n",
    "        label = f'Class {int(best_class)} {best_confidence:.2f}'\n",
    "        \n",
    "        # Draw the best bounding box\n",
    "        draw.rectangle([(x1, y1), (x2, y2)], outline=\"green\", width=3)\n",
    "        \n",
    "        # Draw the label\n",
    "        draw.text((x1, y1 - 10), label, fill=\"green\")\n",
    "        \n",
    "        # Plot the image with the bounding box using Matplotlib\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(pil_image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(f\"No pothole detected in the image: {pothole_id}\")\n",
    "\n",
    "# Usage example:\n",
    "sample_and_predict(model, test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1fb9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
