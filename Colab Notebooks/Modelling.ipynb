{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPQHtgvblM1US847/T4A5Rq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7J5beBu_zT0b","executionInfo":{"status":"ok","timestamp":1723664409916,"user_tz":-120,"elapsed":3700,"user":{"displayName":"Modelling","userId":"17194330630198771738"}},"outputId":"4ea630f3-7cee-4059-d2f4-cf6a550d7134"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tqdm import tqdm\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Concatenate, Dropout, BatchNormalization\n","from tensorflow.keras.applications import EfficientNetB7\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.losses import Huber\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Load your train_df\n","train_df = pd.read_csv('/content/drive/MyDrive/Modelling/train_df.csv')  # Change to your path"]},{"cell_type":"code","source":["# Load and preprocess image data\n","def load_and_preprocess_image(image_path, target_size=(224, 224)):\n","    image = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size)\n","    image = tf.keras.preprocessing.image.img_to_array(image)\n","    image = image / 255.0  # Normalize to [0, 1]\n","    return image\n","\n","# Prepare image data and scalar features\n","image_dir = '/content/drive/MyDrive/Modelling/valid_images'\n","image_paths = []\n","scalar_features = []\n","labels = []\n","\n","for index, row in tqdm(train_df.iterrows()):\n","    pothole_id = row['pothole_id']\n","    image_path = os.path.join(image_dir, f'{pothole_id}.jpg')\n","\n","    if os.path.exists(image_path):\n","        image_paths.append(image_path)\n","        scalar_features.append([\n","            row['pothole_area_mm2'],\n","            row['pothole_length'],\n","            row['pothole_width'],\n","            row['mm_to_pixel_ratio']\n","        ])\n","        labels.append(row['bags_used_rounded'])\n","\n","# Convert lists to numpy arrays\n","images = np.array([load_and_preprocess_image(path) for path in image_paths])\n","scalar_features = np.array(scalar_features)\n","labels = np.array(labels)\n","\n","# Scale scalar features\n","scaler = StandardScaler()\n","scalar_features = scaler.fit_transform(scalar_features)\n","\n","# Save the scaler using pickle\n","scaler_path = '/content/drive/MyDrive/Modelling/scaler.pkl'\n","import pickle\n","with open(scaler_path, 'wb') as f:\n","    pickle.dump(scaler, f)\n","\n","print(f\"Scaler saved to {scaler_path}\")\n","\n","# Split the data into training and validation sets\n","X_train_images, X_val_images, X_train_scalar, X_val_scalar, y_train, y_val = train_test_split(\n","    images, scalar_features, labels, test_size=0.2, random_state=42\n",")\n","\n","# Image augmentation\n","datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jd0L5XFF32iM","executionInfo":{"status":"ok","timestamp":1723664443179,"user_tz":-120,"elapsed":8317,"user":{"displayName":"Modelling","userId":"17194330630198771738"}},"outputId":"b6b62e1c-7171-4611-fb08-ea78403cc9c1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["874it [00:00, 2623.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Scaler saved to /content/drive/MyDrive/Modelling/scaler.pkl\n"]}]},{"cell_type":"code","source":["import pickle\n","scaler_path = '/content/drive/MyDrive/Modelling/scaler.pkl'\n","\n","# Save the scaler using pickle\n","with open(scaler_path, 'wb') as f:\n","    pickle.dump(scaler, f)\n","\n","print(f\"Scaler saved to {scaler_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiReYklAWRhw","executionInfo":{"status":"ok","timestamp":1723665375441,"user_tz":-120,"elapsed":16,"user":{"displayName":"Modelling","userId":"17194330630198771738"}},"outputId":"c550b992-d2fe-446a-c4ca-ea9bd710700d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Scaler saved to /content/drive/MyDrive/Modelling/scaler.pkl\n"]}]},{"cell_type":"code","source":["# Model creation\n","def create_model(input_shape_image, input_shape_scalar):\n","    # Base model: EfficientNetB7\n","    base_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=input_shape_image)\n","    base_model.trainable = False  # Freeze the base model\n","\n","    # Image processing layers\n","    image_input = Input(shape=input_shape_image)\n","    x = base_model(image_input, training=False)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(512, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    x = BatchNormalization()(x)\n","\n","    # Scalar features processing layers\n","    scalar_input = Input(shape=input_shape_scalar)\n","    y = Dense(128, activation='relu')(scalar_input)\n","    y = Dropout(0.5)(y)\n","    y = BatchNormalization()(y)\n","\n","    # Combine the outputs\n","    combined = Concatenate()([x, y])\n","    combined = Dense(128, activation='relu')(combined)\n","    combined = Dropout(0.5)(combined)\n","    combined = BatchNormalization()(combined)\n","\n","    # Output layer\n","    output = Dense(1, activation='relu')(combined)\n","\n","    # Create the model\n","    model = Model(inputs=[image_input, scalar_input], outputs=output)\n","\n","    return model\n","\n","input_shape_image = (224, 224, 3)\n","input_shape_scalar = (scalar_features.shape[1],)\n","model = create_model(input_shape_image, input_shape_scalar)\n","\n","# Use Huber loss with a custom delta value\n","delta = 1.0  # You can adjust this value\n","huber_loss = Huber(delta=delta)\n","\n","# Compile the model with Huber loss\n","model.compile(optimizer=Adam(learning_rate=1e-4), loss='poisson', metrics=['mse'])\n","\n","# Define callbacks\n","checkpoint_path = '/content/drive/MyDrive/Modelling/checkpoints/model_checkpoint.weights.h5'\n","checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_path,\n","    monitor='val_loss',\n","    save_best_only=True,\n","    save_weights_only=True,\n","    mode='min',\n","    verbose=1\n",")\n","\n","early_stopping_callback = EarlyStopping(\n","    monitor='val_loss',\n","    patience=50,\n","    restore_best_weights=True\n",")\n","\n","# Fit the model\n","history = model.fit(\n","    [X_train_images, X_train_scalar], y_train,\n","    validation_data=([X_val_images, X_val_scalar], y_val),\n","    epochs=200,\n","    batch_size=32,\n","    callbacks=[checkpoint_callback, early_stopping_callback],\n","    verbose=1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eq9v6sdt8cth","outputId":"49fbec53-bcb6-4a22-d3da-9c4240920c88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n"]}]},{"cell_type":"code","source":["model.save('/content/drive/MyDrive/Modelling/pothole_bags_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghJF_Qi9_dZw","executionInfo":{"status":"ok","timestamp":1723665375441,"user_tz":-120,"elapsed":21441,"user":{"displayName":"Modelling","userId":"17194330630198771738"}},"outputId":"550f90ee-e530-4fe4-d8e3-5da4aa1aca2f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["model = create_model(input_shape_image, input_shape_scalar)\n","\n","# Load the saved weights\n","checkpoint_path = '/content/drive/MyDrive/Modelling/checkpoints/model_checkpoint.weights.h5'\n","model.load_weights(checkpoint_path)\n","\n","# Compile the model again (required after loading the weights)\n","model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse', metrics=['mse'])\n","\n","checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_path,\n","    monitor='val_loss',\n","    save_best_only=True,\n","    save_weights_only=True,\n","    mode='min',\n","    verbose=1\n",")\n","\n","early_stopping_callback = EarlyStopping(\n","    monitor='val_loss',\n","    patience=10,\n","    restore_best_weights=True\n",")\n","\n","# Continue training\n","history = model.fit(\n","    [X_train_images, X_train_scalar], y_train,\n","    validation_data=([X_val_images, X_val_scalar], y_val),\n","    epochs=50,  # or the number of additional epochs you want to run\n","    batch_size=32,\n","    callbacks=[checkpoint_callback, early_stopping_callback],\n","    verbose=1\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G36jjza3MGLN","outputId":"df68257a-17e7-4914-f8f3-3e7084c518c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]}]}]}