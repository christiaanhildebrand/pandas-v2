{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP4l5JDp09E0y9r5l+9O7LV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from tqdm import tqdm\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Concatenate, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.losses import Huber\n","from google.colab import drive\n","import pickle\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Load your train_df\n","train_df = pd.read_csv('/content/drive/MyDrive/Modelling/train_df.csv')  # Change to your path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SvpTlUc20QYz","executionInfo":{"status":"ok","timestamp":1723703364745,"user_tz":-120,"elapsed":4185,"user":{"displayName":"Chris Hild","userId":"16253994151537008663"}},"outputId":"d505c945-f7be-4a1c-fb27-9a56587e3aaf"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Load and preprocess image data\n","def load_and_preprocess_image(image_path, target_size=(224, 224)):\n","    image = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size)\n","    image = tf.keras.preprocessing.image.img_to_array(image)\n","    image = image / 255.0  # Normalize to [0, 1]\n","    return image\n","\n","# Prepare image data and scalar features\n","image_dir = '/content/drive/MyDrive/Modelling/valid_images'\n","image_paths = []\n","scalar_features = []\n","labels = []\n","\n","for index, row in tqdm(train_df.iterrows()):\n","    pothole_id = row['pothole_id']\n","    image_path = os.path.join(image_dir, f'{pothole_id}.jpg')\n","\n","    if os.path.exists(image_path):\n","        image_paths.append(image_path)\n","        scalar_features.append([\n","            row['pothole_area_mm2'],\n","            row['pothole_length'],\n","            row['pothole_width'],\n","            row['mm_to_pixel_ratio']\n","        ])\n","        labels.append(row['bags_used_rounded'])\n","\n","# Convert lists to numpy arrays\n","images = np.array([load_and_preprocess_image(path) for path in image_paths])\n","scalar_features = np.array(scalar_features)\n","labels = np.array(labels)\n","\n","# Scale scalar features\n","scaler = StandardScaler()\n","scalar_features = scaler.fit_transform(scalar_features)\n","\n","# Save the scaler\n","scaler_path = '/content/drive/MyDrive/Modelling/scaler.pkl'\n","with open(scaler_path, 'wb') as f:\n","    pickle.dump(scaler, f)\n","\n","# Split the data into training and validation sets\n","X_train_images, X_val_images, X_train_scalar, X_val_scalar, y_train, y_val = train_test_split(\n","    images, scalar_features, labels, test_size=0.2, random_state=42\n",")\n","\n","# Image augmentation with scale-preserving transformations\n","data_augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomFlip(\"horizontal\"),\n","    tf.keras.layers.RandomRotation(0.1),\n","    # No random zoom to preserve the scale\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_tVsAAVa0RCA","executionInfo":{"status":"ok","timestamp":1723703342839,"user_tz":-120,"elapsed":8274,"user":{"displayName":"Chris Hild","userId":"16253994151537008663"}},"outputId":"26d4ef53-378d-4c79-d0b0-a23010c9e7b4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["874it [00:00, 1775.78it/s]\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZNB7g1hyHmi","executionInfo":{"status":"ok","timestamp":1723703442894,"user_tz":-120,"elapsed":57284,"user":{"displayName":"Chris Hild","userId":"16253994151537008663"}},"outputId":"ace2fe8f-880a-4586-b2ae-78d3ac1fa404"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 176ms/step - loss: 0.4584 - mse: 1.8848 - r2_score: -75.8476 - val_loss: 0.3288 - val_mse: 1.2247 - val_r2_score: -45.9996 - learning_rate: 1.0000e-04\n","Epoch 2/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 87ms/step - loss: 0.4738 - mse: 1.9592 - r2_score: -83.8022 - val_loss: 0.2570 - val_mse: 0.9832 - val_r2_score: -36.1951 - learning_rate: 1.0000e-04\n","Epoch 3/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.6094 - mse: 3.2712 - r2_score: -67.6413 - val_loss: 0.2384 - val_mse: 0.9088 - val_r2_score: -33.8293 - learning_rate: 1.0000e-04\n","Epoch 4/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.4865 - mse: 1.5286 - r2_score: -84.9013 - val_loss: 0.2258 - val_mse: 0.8644 - val_r2_score: -32.2760 - learning_rate: 1.0000e-04\n","Epoch 5/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.4789 - mse: 2.1386 - r2_score: -76.8274 - val_loss: 0.2200 - val_mse: 0.8471 - val_r2_score: -31.5293 - learning_rate: 1.0000e-04\n","Epoch 6/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.5458 - mse: 2.7535 - r2_score: -68.0311 - val_loss: 0.2858 - val_mse: 1.0592 - val_r2_score: -42.4968 - learning_rate: 1.0000e-04\n","Epoch 7/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.5362 - mse: 2.4785 - r2_score: -65.5203 - val_loss: 0.2215 - val_mse: 0.8519 - val_r2_score: -32.3899 - learning_rate: 1.0000e-04\n","Epoch 8/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.5042 - mse: 2.0979 - r2_score: -74.5031 - val_loss: 0.2809 - val_mse: 1.0290 - val_r2_score: -43.0548 - learning_rate: 1.0000e-04\n","Epoch 9/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.4326 - mse: 1.6875 - r2_score: -73.8416 - val_loss: 0.2346 - val_mse: 0.8893 - val_r2_score: -37.2957 - learning_rate: 1.0000e-04\n","Epoch 10/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4351 - mse: 2.0642 - r2_score: -72.5784\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.4353 - mse: 2.0568 - r2_score: -72.8068 - val_loss: 0.4005 - val_mse: 1.3503 - val_r2_score: -58.4699 - learning_rate: 1.0000e-04\n","Epoch 11/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.4042 - mse: 1.3132 - r2_score: -79.7801 - val_loss: 0.3780 - val_mse: 1.2695 - val_r2_score: -56.8593 - learning_rate: 2.0000e-05\n","Epoch 12/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.3922 - mse: 1.4626 - r2_score: -93.6840 - val_loss: 0.3216 - val_mse: 1.1086 - val_r2_score: -51.1563 - learning_rate: 2.0000e-05\n","Epoch 13/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.4220 - mse: 1.9300 - r2_score: -76.6910 - val_loss: 0.3707 - val_mse: 1.2516 - val_r2_score: -56.0211 - learning_rate: 2.0000e-05\n","Epoch 14/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.4260 - mse: 1.8332 - r2_score: -86.4705 - val_loss: 0.4093 - val_mse: 1.3754 - val_r2_score: -59.4380 - learning_rate: 2.0000e-05\n","Epoch 15/100\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4073 - mse: 1.5270 - r2_score: -80.7266\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.4090 - mse: 1.5446 - r2_score: -80.6635 - val_loss: 0.2785 - val_mse: 0.9504 - val_r2_score: -48.9743 - learning_rate: 2.0000e-05\n"]}],"source":["def r2_score(y_true, y_pred):\n","    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n","    ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n","    return 1 - ss_res / (ss_tot + tf.keras.backend.epsilon())\n","\n","def create_model(input_shape_image, input_shape_scalar):\n","    # Image processing layers\n","    image_input = Input(shape=input_shape_image)\n","    x = data_augmentation(image_input)\n","    x = Conv2D(32, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Conv2D(64, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Conv2D(128, (3, 3), activation='relu')(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Flatten()(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    x = BatchNormalization()(x)\n","\n","    # Scalar features processing layers\n","    scalar_input = Input(shape=input_shape_scalar)\n","    y = Dense(64, activation='relu')(scalar_input)\n","    y = Dropout(0.5)(y)\n","    y = BatchNormalization()(y)\n","\n","    # Combine the outputs\n","    combined = Concatenate()([x, y])\n","    combined = Dense(64, activation='relu')(combined)\n","    combined = Dropout(0.5)(combined)\n","    combined = BatchNormalization()(combined)\n","\n","    # Output layer with ReLU to prevent negative values\n","    output = Dense(1, activation='relu')(combined)\n","\n","    # Create the model\n","    model = Model(inputs=[image_input, scalar_input], outputs=output)\n","\n","    return model\n","\n","# Model creation\n","input_shape_image = (224, 224, 3)\n","input_shape_scalar = (scalar_features.shape[1],)\n","model = create_model(input_shape_image, input_shape_scalar)\n","\n","# Compile the model with Huber loss for robustness\n","model.compile(optimizer=Adam(learning_rate=1e-4), loss=Huber(), metrics=['mse', r2_score])\n","\n","# Callbacks\n","early_stopping_callback = EarlyStopping(\n","    monitor='val_loss',\n","    patience=10,\n","    restore_best_weights=True\n",")\n","\n","reduce_lr_callback = ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.2,\n","    patience=5,\n","    min_lr=1e-7,\n","    verbose=1\n",")\n","\n","# Fit the model\n","history = model.fit(\n","    [X_train_images, X_train_scalar], y_train,\n","    validation_data=([X_val_images, X_val_scalar], y_val),\n","    epochs=100,\n","    batch_size=32,\n","    callbacks=[early_stopping_callback, reduce_lr_callback],\n","    verbose=1\n",")\n","\n","# Save the model\n","model.save('/content/drive/MyDrive/Modelling/own_CNN.keras')"]},{"cell_type":"code","source":["model_save_path_h5 = '/content/drive/MyDrive/Modelling/own_CNN.h5'\n","\n","# Save the model in HDF5 format\n","model.save(model_save_path_h5)\n","\n","print(f\"Model saved to {model_save_path_h5}\")"],"metadata":{"id":"dc4JiqZO0p1z","executionInfo":{"status":"aborted","timestamp":1723703332588,"user_tz":-120,"elapsed":2,"user":{"displayName":"Chris Hild","userId":"16253994151537008663"}}},"execution_count":null,"outputs":[]}]}